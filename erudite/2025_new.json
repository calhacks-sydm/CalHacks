[{"question_id": "Fall_2021_1", "topic": "Dynamic Programming", "question_description": "Write a dynamic programming recurrence to count f(n,m), the number of distinct shortest paths in a 2D integer grid from (0,0) to (n,m), where n and m are positive integers. You can only travel along the x and y directions (no diagonals).", "answer": "f(n,m) = f(n-1,m) + f(n,m-1)", "hint": "Think of the problem as a sequence of subproblems that build on each other. Consider the base cases and how the recurrence relates to them.", "subproblem": [{"title": "Base cases", "description": "What are the base cases for the recurrence? What is the value of f(0,m) and f(n,0)?"}, {"title": "Recurrence relation", "description": "How does the recurrence relation relate to the base cases? How does it build on the previous subproblems?"}], "simplifiedAns": "To solve this problem, we can use dynamic programming to build a recurrence relation. Let's define f(n,m) as the number of distinct shortest paths in a 2D integer grid from (0,0) to (n,m), where n and m are positive integers.\n\nTo understand the solution, let's consider a simple analogy. Imagine you are standing at the bottom left corner of a grid and you want to reach the top right corner. You can only move either right or up, but not diagonally. Your goal is to count the number of different paths you can take to reach the top right corner.\n\nNow, let's break down the problem. To reach the top right corner, you have two options: either move right or move up. If you move right, you will end up at the cell (n-1,m), and if you move up, you will end up at the cell (n,m-1). \n\nTherefore, the number of distinct shortest paths to reach the cell (n,m) is equal to the sum of the number of distinct shortest paths to reach the cell (n-1,m) and the number of distinct shortest paths to reach the cell (n,m-1). This can be represented by the recurrence relation: f(n,m) = f(n-1,m) + f(n,m-1).\n\nBy using this recurrence relation, we can build a dynamic programming solution. We start by initializing f(0,0) = 1, as there is only one way to reach the starting cell. Then, we can iteratively calculate f(n,m) for all cells in the grid, using the recurrence relation.\n\nIn each iteration, we calculate f(n,m) by adding the number of distinct shortest paths from the cell above (n-1,m) and the cell to the left (n,m-1). By doing this, we consider all possible paths and avoid counting the same path multiple times.\n\nFinally, when we reach the top right corner, we will have the value of f(n,m), which represents the number of distinct shortest paths from (0,0) to (n,m) in the 2D grid.\n\nIn summary, the dynamic programming recurrence f(n,m) = f(n-1,m) + f(n,m-1) allows us to count the number of distinct shortest paths in a 2D integer grid from (0,0) to (n,m), where n and m are positive integers. This can be visualized as finding the number of different paths to reach the top right corner of a grid, where you can only move right or up."}, {"question_id": "Fall_2021_2", "topic": "Dynamic Programming", "question_description": "State clearly whether the given statement is true or false and give a brief justification for your answer.\n\n(a) There exists a graph with 3 vertices such that the lowest postorder number of any DFS on the graph is not in a sink SCC.\n\n(b) Let f: N > {0,1,2,3,4} = 3x+4 (mod 5). Then H = {f}, where H constitutes of that single function f, is a universal hash family of functions: N > {0,1,2,3,4}.\n\n(c) Let the output of the Morris algorithm for an approximate counting of a stream of n numbers be ii. Then the difference between n and fi (i.e. |n - ii|) is bounded by a constant.\n\n(d) We don't need to calculate the 7th roots of unity to calculate the FFT of a length 7 vector.\n\n(e) Vi = OV", "answer": "(a) False, starting a DFS from any vertex in a sink SCC will have the lowest postorder number in that SCC.\n(b) False. Pick x = 1 and y = 6. f(1) = f(6) = 2 (mod 5), for this x, y we have collision probability of 1, which makes H non-universal.\n(c) False. It's bounded by (0, | (resulting from experiencing no update every time or experiencing update every time), which grows as n grows. The only practical bound is the probability of exceeding relative error (|n - fi| < eN).\n(d) True. We pad the vector to length-8 and we use 1, 2, 4, 8th roots of unity for the calculation. We need to round up the length and pad these vectors to the nearest power of 2, 8, for FFT on length 7 vectors. (Evaluating at 7 points also works for DFT, but we can't divide-and-conquer.)\n(e) False, through L'Hopital's", "hint": "Remember to check for collisions when determining whether a hash family is universal. Also, consider the practical bound when determining whether the difference between n and fi is bounded by a constant.", "subproblem": [{"title": "Checking for collisions in a hash family", "description": "To determine whether a hash family is universal, check for collisions by picking two arbitrary values x and y and seeing if f(x) = f(y) (mod 5)."}, {"title": "Determining the practical bound", "description": "To determine whether the difference between n and fi is bounded by a constant, consider the probability of exceeding relative error (|n - fi| < eN)."}], "simplifiedAns": "(a) False. Starting a DFS from any vertex in a sink SCC will have the lowest postorder number in that SCC. This is because a sink SCC is a strongly connected component where all vertices can reach each other, so starting a DFS from any vertex in the SCC will visit all vertices in the SCC before moving on to other components.\n\n(b) False. Let's consider the function f(x) = 3x + 4 (mod 5). If we take x = 1 and y = 6, we get f(1) = f(6) = 2 (mod 5). This means that there is a collision, which violates the requirement for a universal hash family where each pair of distinct inputs should have a low collision probability.\n\n(c) False. The output of the Morris algorithm for approximate counting of a stream of n numbers, denoted as ii, is an approximation of the count. The difference between n and ii, |n - ii|, is not bounded by a constant. It can vary depending on the specific stream of numbers and the accuracy of the approximation algorithm.\n\n(d) True. We don't need to calculate the 7th roots of unity to calculate the FFT (Fast Fourier Transform) of a length 7 vector. Instead, we can pad the vector to a length of 8 and use the 1st, 2nd, 4th, and 8th roots of unity for the calculation. The FFT algorithm requires the vector length to be a power of 2, so we round up the length to the nearest power of 2 (8 in this case) and pad the vector accordingly.\n\n(e) False. The statement \"Vi = OV\" is not clear and lacks context. Without further information, it is not possible to determine the truth value of this statement."}, {"question_id": "Fall_2021_3", "topic": "Reductions, Bipartite Matching", "question_description": "State clearly whether the given statements are True, True iff P = NP, True iff P != NP, or False and give a brief justification for your answer.\n\n(a) There exists a polynomial time reduction from 3SAT to Palindrome Checking. Assume that Palindrome Checking is a program that verifies if a given word is a palindrome or not.\n\n(b) There exists a polynomial time reduction from any NP hard problem to any other NP hard problem.\n\n(c) There exists a polynomial time reduction from Palindrome Checking to 3SAT.", "answer": "(a) True iff P = NP. If P = NP, we can solve 3-SAT in polynomial time by reducing it in polynomial time to some problem in P. Solve 3-SAT, then create a trivial word which is a palindrome iff the 3-SAT instance is satisfiable. This gives a polynomial time reduction from 3-SAT to Palindrome Checking. A polynomial-time reduction from 3-SAT to Palindrome Checking together with the polynomial time algorithm for Palindrome Checking implies a polynomial-time algorithm for 3-SAT and thus implies P=NP.\n(b) False. The Halting problem which is NP hard cannot be reduced to 3 SAT which is also NP hard.\n(c) True, you can solve Palindrome Checking in polynomial time and then create a trivial 3 SAT instance that evaluates to True if Palindrome Checking evaluated to True and False otherwise.", "hint": "Think about the implications of a polynomial time reduction from one problem to another. What does it mean if one problem can be reduced to another in polynomial time?", "subproblem": [{"title": "What is a polynomial time reduction?", "description": "A polynomial time reduction is a transformation of one problem into another such that the solution of the transformed problem can be used to solve the original problem in polynomial time."}, {"title": "What does it mean if one problem can be reduced to another in polynomial time?", "description": "If one problem can be reduced to another in polynomial time, it means that the solution of the transformed problem can be used to solve the original problem in polynomial time. This implies that the original problem can be solved in polynomial time as well."}], "simplifiedAns": "(a) True iff P = NP. If P = NP, we can solve 3-SAT in polynomial time by reducing it in polynomial time to some problem in P. Solve 3-SAT, then create a trivial word which is a palindrome iff the 3-SAT instance is satisfiable. This gives a polynomial time reduction from 3-SAT to Palindrome Checking. A polynomial-time reduction from 3-SAT to Palindrome Checking together with the polynomial time algorithm for Palindrome Checking implies a polynomial-time algorithm for 3-SAT and thus implies P=NP.\n\n(b) False. The Halting problem which is NP hard cannot be reduced to 3 SAT which is also NP hard.\n\n(c) True iff P != NP. You can solve Palindrome Checking in polynomial time and then create a trivial 3 SAT instance that evaluates to True if Palindrome Checking evaluated to True and False otherwise. However, this reduction does not imply P=NP, as it only shows that Palindrome Checking can be reduced to 3-SAT, not the other way around."}, {"question_id": "Fall_2021_4", "topic": "Greedy Algorithms", "question_description": "The CS 170 course staff is planning a road trip to Guinland. Originally, Param was in charge of seating assignments in cars for all members of the course staff. He arranged p people in n cars where car i has capacity c_i. However, given Param's poor planning skills, he assigned people in cars terribly inefficiently leaving a lot of empty space in many cars. Given the number of people p, and the capacities of each of the n cars C_1,...,C_n, come up with an efficient greedy algorithm to fit people in cars such that the CS 170 course staff can take the least number of cars possible on the road trip.", "answer": "Sort the cars in descending order of capacity and while there's unassigned people (p > 0) choose the next biggest car and assign min(c_i, p) to that car. Then update p = p - c_i.", "hint": "Think about how you can use the greedy approach to solve this problem.", "subproblem": [{"title": "Sorting the cars", "description": "Sort the cars in descending order of capacity."}, {"title": "Assigning people to cars", "description": "Choose the next biggest car and assign min(c_i, p) to that car. Then update p = p - c_i."}], "simplifiedAns": "In this problem, we have a group of people who are going on a road trip to Guinland. They are divided into cars, and each car has a certain capacity. However, the person in charge of assigning people to cars did a poor job and left many cars with empty seats.\n\nTo solve this problem efficiently, we can use a greedy algorithm. The idea is to sort the cars in descending order of their capacity. This way, we can start with the car that has the most seats available.\n\nThen, we iterate through the cars and assign people to them. We start with the car that has the highest capacity and assign as many people as possible to that car. We continue this process until we have assigned all the people to cars or until there are no more people left.\n\nTo assign people to a car, we take the minimum of the car's capacity and the number of remaining unassigned people. This ensures that we don't assign more people to a car than it can accommodate.\n\nAfter assigning people to a car, we update the number of remaining unassigned people by subtracting the number of people assigned to that car.\n\nBy following this algorithm, we can efficiently assign people to cars and minimize the number of cars needed for the road trip.\n\nTo understand this algorithm better, let's consider an analogy. Imagine you have a group of friends who want to go to a concert. Each friend has a ticket, and there are different sizes of cars available. However, the person in charge of organizing the trip didn't do a good job and left many cars with empty seats.\n\nTo solve this problem, you can sort the cars based on their size, starting with the car that can accommodate the most people. Then, you can assign friends to the cars, starting with the largest car. You assign as many friends as possible to that car without exceeding its capacity. After assigning friends to a car, you update the number of remaining friends.\n\nBy following this approach, you can efficiently fill the cars and minimize the number of cars needed for the trip."}, {"question_id": "Fall_2021_5", "topic": "Graph Algorithms", "question_description": "Thanks to your efforts on the project, CS 170's igloo polishing venture is flourishing! In an attempt to cut costs and further maximize profits, CS 170 now needs your help figuring out the cheapest way to get from one igloo polishing task to the next. Our clients are spread out in the vast kingdom of Guinland which consists of |V| cities. Assume that no two consecutive polishing jobs are in the same city.\n\nThe |V| cities of Guinland are connected by |E| directed edges which can be used to travel from one city to another, i.e. we can use an edge (u,v) to travel from city u to another city v. To travel from one city u to another city v we can use either cable car, snowmobiles, or trains which have strictly positive costs C_o(u,v), C_s(u,v), and C_t(u,v) respectively. If you can travel from city u to city v, you can use any of the three modes of transport, i.e. if the directed edge (u,v) exists, all 3 modes of transport will be available between u and v each with their own respective costs.\n\nUnfortunately, for some bizarre reason, we cannot take any same mode of transportation twice in a row, i.e., we cannot enter city u on a snowmobile and leave city u on a snowmobile, and the same applies for cable cars and trains. Given a directed graph representation of Guinland G = (V,E) and cities s and t, come up with an algorithm that helps us find the cheapest path between city s and city t in G and analyze its runtime. No need for a proof of correctness.", "answer": "We will create a new graph G' where each city v (except s and t) is represented by three vertices: U_c, U_s, and U_t. U_c corresponds to coming to v via cable car, U_s corresponds to coming to v via snowmobile, and U_t corresponds to coming to v via train. If we can travel between cities v and u, then add the following six edges to G': (U_c, U_s), (U_c, U_t), (U_s, U_c), (U_s, U_t), (U_t, U_c), (U_t, U_s). The weights of edges are the positive costs of transportation. This construction forces the edges to satisfy the requirement that we cannot travel via the same means of transportation subsequently. Then, for each city v such that we can travel from s to v, add edges (s, U_c), (s, U_s), (s, U_t) with corresponding weights. For each vertex v from which we can travel to t, add edges (U_c, t), (U_s, t), (U_t, t) with corresponding weights. Finally, run Dijkstra's Algorithm on G' from s and return the shortest distance from s to t.", "hint": "Think about how to represent the different means of transportation and how to enforce the restriction of not using the same means of transportation twice in a row.", "subproblem": []}, {"question_id": "Fall_2021_6", "topic": "Greedy Algorithms", "question_description": "It's Adnaan's birthday today and the CS 170 staff are shopping presents for him in a shop. There are n items on the shopping list. The shop is doing a peculiar holiday sale: there are m \"works well together\" unordered pairs (i,j), k \u00e2\u02c6\u02c6 {1,...,m}; i,j \u00e2\u02c6\u02c6 {1,...,n}. For the k-th pair (k \u00e2\u02c6\u02c6 {1,...,m}), if you have already bought one item in the pair from the store, you are allowed to buy the other item in the pair for the price of d_k dollars instead of its original price. Given (e_x)_{1\u00e2\u2030\u00a4x\u00e2\u2030\u00a4m}, (d_x)_{1\u00e2\u2030\u00a4x\u00e2\u2030\u00a4m}, and the original price of the n items (p_x)_{1\u00e2\u2030\u00a4x\u00e2\u2030\u00a4n}, design an algorithm that outputs\n\n- the least amount of money the staff could spend to buy all n items and\n- a possible order of buying the n items that achieves this least amount of money.", "answer": "Utilize the hint. We note that MST algorithms pick |V| - 1 edges in a graph with |V| vertices. Since we wish to pick n items, we create a graph with n + 1 vertices, one for each item and one \"dummy\" vertex. Then, we connect all item vertices to the dummy vertex with edge weight equal to the price of the item. We also connect \"works well together\" vertices with edge weight equal to \"works well together\" price. Note that if you possess one item in the pair, you may purchase the other item with price d_x, regardless of which item you bought first. Now we find MST in this graph. Starting from the dummy node, we perform any search to get some order to traverse the tree. We purchase in the order which we visit the vertices that represent corresponding items.", "hint": "Utilize the hint given in the question to come up with a solution that minimizes the cost of buying all items.", "subproblem": []}, {"question_id": "Fall_2021_7", "topic": "Reductions", "question_description": "Define the FALSY-SAT problem as follows:\n\nGiven a 3-CNF boolean formula \u00cf\u2020, decide if there's an assignment to the variables of \u00cf\u2020 that satisfies without containing three true literals in any clause.\n\nIn other words, a FALSY-SAT instance is satisfied if and only if exactly 1 or 2 literal(s) in each clause is/are assigned to true.\n\n(a) Give a polynomial time reduction from 3SAT to FALSY-SAT by replacing each clause c_i = (a_1 V a_2 V a_3) with the two clauses (a_1 V a_2 V b_i) and (b_i V a_3 V t), where b_i is a new variable for each clause c_i and t is a single additional new variable.", "answer": "The reduction is as follows: If the original clause is satisfiable because of a_1 or a_2 but not a_3, FALSY-SAT instance can set b_i to be false, making the first clause satisfied; the second clause is also satisfied with a true b_i and a false a_3. If the original clause is satisfiable because of a_3 but not a_1 and a_2, FALSY-SAT instance can set b_i to be true, making the second clause satisfied with a false b_i and a true a_3 and making the first clause satisfied with a true b_i and two false literals. The above two cases have no t involved. Nevertheless, if the original clause is satisfiable by all three literals, set b_i to be false and t to be false, we observe the new clauses are satisfiable.", "hint": "Think about how to transform the original 3SAT instance into a FALSY-SAT instance by introducing new variables and clauses.", "subproblem": []}, {"question_id": "Fall_2021_8", "topic": "Approximation Algorithms", "question_description": "In class we saw that there is a 2-approximation algorithm for set cover. In this problem, we will first see another approximation algorithm for set cover (part (a)), then we will discover how randomness could give us a much better algorithm (part (b) through (d)).\n\n(a) Show that if no element is contained in more than k sets, then there is a polynomial-time k-approximation algorithm for set cover by using the linear programming relaxation obtained by removing the integrality constraints. Specifically, you should describe how to obtain a solution from the relaxed linear program without integrality constraints, show your algorithm works (i.e. all items will be covered), and prove the approximation factor is k.", "answer": "Algorithm: Solve the relaxed LP. For each x_i, round it up to 1 if x_i > 1/k; otherwise round it down to 0.", "hint": "Think about how to use the relaxed linear program to obtain a solution that covers all items while minimizing the number of sets used.", "subproblem": []}]